{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tensors by default will be created as Float and on cuda device, most of these tensors will be created in render only.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "References: https://pytorch3d.org/tutorials/fit_simple_neural_radiance_field\n",
    "https://github.com/yenchenlin/nerf-pytorch\n",
    "'''\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import mlflow\n",
    "import plotly.express as px\n",
    "from src.utils import visualize_plotly\n",
    "import pytorch3d\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from src.get_bottles import get_data, MyCam\n",
    "from src.Network import NeuralRadianceField_torch\n",
    "from src.ray_utils import get_rays_all_files, ray_march, get_pts_from_ray_batch, hier_sample\n",
    "\n",
    "# obtain the utilized device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    torch.cuda.set_device(device)\n",
    "    print(\"All tensors by default will be created as Float and on cuda device, most of these tensors will be created in render only.\")\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    print('CPU being used, check once!!' )\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_figs = True\n",
    "if display_figs:   \n",
    "    from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_path:  pred/fine_trained_bottles_200000_800_180_8_2/\n",
      "======NO MLFLOW========\n"
     ]
    }
   ],
   "source": [
    "viz_freq = 500\n",
    "viz_train = False\n",
    "val_freq = 100\n",
    "\n",
    "## Args\n",
    "args = {}\n",
    "args['zfar'] = 6.0\n",
    "args['znear'] = 0.5\n",
    "\n",
    "args['dataset'] = 'bottles' # [bottles, cow]\n",
    "args['image_size'] = 800\n",
    "resize_ratio = args['image_size']/800\n",
    "# args['train_size'] = 180    # max (200 - val_size)\n",
    "args['val_size'] = 1\n",
    "files_to_be_validated = None\n",
    "args['white_bkg'] = True\n",
    "\n",
    "# args['learning_rate'] = 5e-4\n",
    "# args['num_iterations'] = 40000\n",
    "args['accum_iter'] = 2\n",
    "# args['num_iterations'] after counting gradient accumulation\n",
    "# args['num_iterations'] *= args['accum_iter']\n",
    "\n",
    "args['n_rays_per_batch'] = 4096 // args['accum_iter']\n",
    "args['n_pts_per_ray'] = 256\n",
    "args['n_heir_pts_per_ray'] = 256\n",
    "args['stratified_sampling'] = True\n",
    "\n",
    "args['num_layers'] = 8\n",
    "skip_attach_after = 5\n",
    "args['skips']=[skip_attach_after-1] if skip_attach_after is not None else []\n",
    "\n",
    "args['coarse_fn_path'] = 'models/copies/bottles_100000_800_180_8_1.tar'\n",
    "args['checkpoint'] = 'models/fine_trained_bottles_200000_800_180_8_2.tar'\n",
    "_prefix = '' if args['coarse_fn_path'] is None else 'fine_trained'\n",
    "\n",
    "assert args['checkpoint'] is not None\n",
    "\n",
    "if args['coarse_fn_path'] is not None:\n",
    "    args['init_fine_fn'] = True # Only useful if 'checkpoint' is not mentioned else checkpoint overrides it.\n",
    "\n",
    "args['pred_save_path'] = f\"pred/{Path(args['checkpoint']).stem}/\"\n",
    "os.makedirs(args['pred_save_path'],exist_ok=True)\n",
    "args['n_harmonic_functions_pos'] = 10\n",
    "args['n_harmonic_functions_dir'] = 4\n",
    "n_harmonic_functions = 10\n",
    "\n",
    "print('pred_path: ', args['pred_save_path'])\n",
    "\n",
    "log_mlflow = False\n",
    "if log_mlflow:\n",
    "    args['description'] = \"Without positional encoding\"\n",
    "    try:\n",
    "        mlflow.end_run()\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    mlflow.set_experiment('Default')\n",
    "    mlflow.start_run()\n",
    "    print(\"runid: \", mlflow.active_run().info.run_id)\n",
    "\n",
    "    mlflow.log_params(args)\n",
    "else:\n",
    "    print(\"======NO MLFLOW========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "# Instantiate the radiance field model.\n",
    "neural_radiance_field = NeuralRadianceField_torch(D = args['num_layers'],\n",
    "                                            skips = args['skips'],\n",
    "                                            n_harmonic_functions_pos = args['n_harmonic_functions_pos'],\n",
    "                                           n_harmonic_functions_dir = args['n_harmonic_functions_dir']).to(device)\n",
    "\n",
    "# Load the coarse model\n",
    "if args['coarse_fn_path'] is not None:\n",
    "    coarse_nerf = NeuralRadianceField_torch(D = args['num_layers'],\n",
    "                                                skips = args['skips'],\n",
    "                                                n_harmonic_functions_pos = args['n_harmonic_functions_pos'],\n",
    "                                            n_harmonic_functions_dir = args['n_harmonic_functions_dir']).to(device)\n",
    "\n",
    "    coarse_nerf.load_state_dict(torch.load(args['coarse_fn_path'])['model_state_dict'])\n",
    "else:\n",
    "    coarse_nerf = None\n",
    "\n",
    "\n",
    "ckpt = torch.load(args['checkpoint'])\n",
    "neural_radiance_field.load_state_dict(ckpt['model_state_dict'])\n",
    "\n",
    "\n",
    "train_files_ckpt = ckpt['train_files']\n",
    "args['train_size'] = len(train_files_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data: Numpy Land\n",
    "def split(tensor, tsize):\n",
    "    return tensor[:-tsize], tensor[-tsize:]\n",
    "\n",
    "def split_cameras(cameras, tsize):\n",
    "    args = cameras.get()\n",
    "    c2ws_split = split(args[-1],tsize)\n",
    "    return MyCam(*args[:-1], c2ws_split[0]), MyCam(*args[:-1], c2ws_split[1])\n",
    "\n",
    "files, cameras, images, silhouettes = get_data(train_not_test = True, num_files = args['train_size'] + args['val_size'], resize_ratio = resize_ratio)\n",
    "\n",
    "train_files, val_files = split(files, args['val_size'])\n",
    "train_images, val_images = split(images, args['val_size'])\n",
    "train_sil, val_sil = split(silhouettes, args['val_size'])\n",
    "train_cameras, val_cameras = split_cameras(cameras, args['val_size'])\n",
    "\n",
    "if files_to_be_validated is not None:\n",
    "    indices = [i for i,v in enumerate(val_files) if v in files_to_be_validated]\n",
    "\n",
    "    val_files = [val_files[idx] for idx in indices]\n",
    "    cam_params = val_cameras.get()\n",
    "    val_c2ws = [cam_params[-1][idx] for idx in indices]\n",
    "    val_cameras = MyCam(*cam_params[:-1], val_c2ws)\n",
    "\n",
    "    val_sil = None\n",
    "    val_images = np.zeros((len(val_files), args['image_size'], args['image_size'], 3))\n",
    "\n",
    "\n",
    "assert train_files == train_files_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files, test_cameras = get_data(train_not_test = False, num_files = np.inf, resize_ratio = resize_ratio)\n",
    "files_to_be_tested = ['bottles/pose/2_test_0000.txt', 'bottles/pose/2_test_0016.txt', 'bottles/pose/2_test_0055.txt', 'bottles/pose/2_test_0093.txt', 'bottles/pose/2_test_0160.txt']\n",
    "indices = [i for i,v in enumerate(test_files) if v in files_to_be_tested]\n",
    "\n",
    "test_files = [test_files[idx] for idx in indices]\n",
    "cam_params = test_cameras.get()\n",
    "test_c2ws = [cam_params[-1][idx] for idx in indices]\n",
    "test_cameras = MyCam(*cam_params[:-1], test_c2ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rays_rgb = get_rays_all_files(test_cameras, np.zeros((len(test_files), args['image_size'], args['image_size'], 3)), shuffle = False) # [N*H*W, 3(ro+rd+rgb), 3]\n",
    "val_rays_rgb = get_rays_all_files(val_cameras, val_images, shuffle = False) # Unshuffled, will be used for generating full size render\n",
    "## Torch land start, notice rays are not put on the gpu, sometimes they can be huge in size\n",
    "test_rays_rgb = torch.tensor(test_rays_rgb, device='cpu') # Have to explicitly put 'cpu', as new tensors by default are on cuda\n",
    "val_rays_rgb = torch.tensor(val_rays_rgb, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render works in torch land, i.e. everything is in torch\n",
    "def render_coarse(ray_batch, nerf_fun):\n",
    "    # Create needed variables\n",
    "    rays_o, rays_d = ray_batch\n",
    "    viewdirs = rays_d / torch.norm(rays_d, dim=-1, keepdim=True) # [N_rays, 3]\n",
    "    near, far = args['znear'] * torch.ones_like(rays_d[...,:1]), args['zfar'] * torch.ones_like(rays_d[...,:1])\n",
    "\n",
    "    pts, z_vals = get_pts_from_ray_batch(rays_o, rays_d, near, far, args['n_pts_per_ray'], args['stratified_sampling']) # [N_rays, N_samples, 3]\n",
    "    \n",
    "    # Needed to allow concatenating with the features in the model\n",
    "    viewdirs = viewdirs[:,None].expand(pts.shape)   # [N_rays, N_samples, 3]\n",
    "    \n",
    "    c_sigma  = nerf_fun(torch.cat([pts, viewdirs], -1)) # [N_rays, N_samples, 4]\n",
    "\n",
    "    rgb_map, weights, depth_map = ray_march(c_sigma, z_vals, rays_d, white_bkgd = args['white_bkg'])\n",
    "\n",
    "    return rgb_map, weights, depth_map, z_vals\n",
    "\n",
    "def render_fine(ray_batch, z_vals, nerf_fun):\n",
    "    # Create needed variables\n",
    "    rays_o, rays_d = ray_batch\n",
    "    viewdirs = rays_d / torch.norm(rays_d, dim=-1, keepdim=True) # [N_rays, 3]\n",
    "    \n",
    "    pts = rays_o[...,None,:] + rays_d[...,None,:] * z_vals[...,:,None] # [N_rays, N_samples + N_importance, 3]\n",
    "    \n",
    "    # Needed to allow concatenating with the features in the model\n",
    "    viewdirs = viewdirs[:,None].expand(pts.shape)   # [N_rays, N_samples, 3]\n",
    "    \n",
    "    c_sigma  = nerf_fun(torch.cat([pts, viewdirs], -1)) # [N_rays, N_samples, 4]\n",
    "\n",
    "    rgb_map, weights, depth_map = ray_march(c_sigma, z_vals, rays_d, white_bkgd = args['white_bkg'])\n",
    "\n",
    "    return rgb_map, weights, depth_map, z_vals\n",
    "\n",
    "def render(ray_batch, nerf_fun, coarse_nerf_fun):\n",
    "    if coarse_nerf_fun is None:\n",
    "        rgb_map, weights, depth_map, _ = render_coarse(ray_batch, nerf_fun)\n",
    "        return rgb_map, weights, depth_map\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            _, weights, _, z_vals = render_coarse(ray_batch, coarse_nerf_fun)\n",
    "            z_samples = hier_sample(z_vals, weights, args['n_heir_pts_per_ray'])\n",
    "        z_vals, _ = torch.sort(torch.cat([z_vals, z_samples], -1), -1)  # [N_rays, n_pts + n_hier_pts]\n",
    "        rgb_map, weights, depth_map, _ = render_fine(ray_batch, z_vals, nerf_fun)\n",
    "        return rgb_map, weights, depth_map\n",
    "    \n",
    "\n",
    "def chunk_render(rays, nerf_fun):\n",
    "    chunk=args['n_rays_per_batch']\n",
    "    outs = [[] for _ in range(3)]\n",
    "    for idx in range(0, rays.shape[0], chunk):\n",
    "        print(\"chunk idx: \", idx)\n",
    "        o = render(rays[idx:idx+chunk], nerf_fun)\n",
    "        for i,val in enumerate(o):\n",
    "            outs[i].append(val)\n",
    "    return [torch.cat(m, 0) for m in outs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2mse = lambda x, y : torch.mean((x - y) ** 2)\n",
    "mse2psnr = lambda x : -10. * torch.log(x) / torch.log(torch.Tensor([10.]))\n",
    "\n",
    "def log_stuff(loss, psnr, hist_col, hist_psnr, prefix, iter):\n",
    "    # Log the loss history.\n",
    "    hist_col.append(float(loss))\n",
    "    hist_psnr.append(float(psnr))\n",
    "    if log_mlflow:\n",
    "        mlflow.log_metrics({prefix + ' loss color': float(loss), prefix + ' psnr': float(psnr)}, step=iter//args['accum_iter'])\n",
    "\n",
    "def get_loss_psnr_from_batch(batch, nerf_fun, coarse_nerf_fun, render_fn, val):\n",
    "    batch = torch.transpose(batch, 0, 1)\t# [2+1, B, 3]\n",
    "    batch_rays, target_s = batch[:2], batch[2]\n",
    "\n",
    "    was_not_on_cuda = not batch_rays.is_cuda\n",
    "\n",
    "    if was_not_on_cuda:\n",
    "        batch_rays = batch_rays.to(device)\n",
    "        target_s = target_s.to(device)\n",
    "\n",
    "    if not val:\n",
    "        rgb_map, weights, depth_map = render_fn(batch_rays, nerf_fun, coarse_nerf_fun)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            rgb_map, weights, depth_map = render_fn(batch_rays, nerf_fun, coarse_nerf_fun)\n",
    "\n",
    "    loss = img2mse(rgb_map, target_s)\n",
    "    psnr = mse2psnr(loss)\n",
    "\n",
    "    if was_not_on_cuda:\n",
    "        batch_rays = batch_rays.to('cpu')\n",
    "        target_s = target_s.to('cpu')\n",
    "\n",
    "    return loss, psnr, rgb_map, depth_map, target_s\n",
    "\n",
    "def get_loss_psnr(rays_rgb, nerf_fun, coarse_nerf_fun, val, i_batch = None):\n",
    "    if i_batch is not None:\n",
    "        batch = rays_rgb[i_batch:i_batch+args['n_rays_per_batch']] # [B, 2+1, 3]\n",
    "        i_batch += args['n_rays_per_batch']\n",
    "        if i_batch >= rays_rgb.shape[0]:\n",
    "            # Shuffle data after an epoch as in implementation!\n",
    "            rand_idx = torch.randperm(rays_rgb.shape[0])\n",
    "            rays_rgb = rays_rgb[rand_idx]\n",
    "            i_batch = 0\n",
    "    else:\n",
    "        batch = rays_rgb[torch.randperm(rays_rgb.shape[0])[:args['n_rays_per_batch']]]\n",
    "\n",
    "    loss, psnr, rgb_map, depth_map, target_s = get_loss_psnr_from_batch(batch, nerf_fun, coarse_nerf_fun, render, val)\n",
    "\n",
    "    return loss, psnr, rays_rgb, i_batch, rgb_map, depth_map, target_s\n",
    "\n",
    "def get_item_from_unshuffled(rays, i):\n",
    "    l, u = i*(args['image_size']*args['image_size']), (i+1)*(args['image_size']*args['image_size'])\n",
    "    return rays[l:u, :, :]\n",
    "\n",
    "def render_full_size_on_cpu(rays_rgb, nerf_fun, coarse_nerf_fun):\n",
    "    i_batch = 0\n",
    "    r_maps, d_maps, tars = [], [], []\n",
    "    while True:\n",
    "        _, _, rays_rgb, i_batch, rgb_map, depth_map, target_s = get_loss_psnr(rays_rgb, nerf_fun, coarse_nerf_fun, True, i_batch)\n",
    "        r_maps.append(rgb_map.to('cpu'))\n",
    "        d_maps.append(depth_map.to('cpu'))\n",
    "        tars.append(target_s.to('cpu'))\n",
    "        if i_batch == 0:\n",
    "            break\n",
    "    return torch.cat(r_maps, 0), torch.cat(d_maps, 0), torch.cat(tars, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def show_full_render(\n",
    "    nerf_fun, coarse_nerf_fun, device, rays_rgb,\n",
    "    tcolor, tpsnr, vcolor, vpsnr,\n",
    "):\n",
    "    \"\"\"\n",
    "    This is a helper function for visualizing the\n",
    "    intermediate results of the learning. \n",
    "    \n",
    "    Since the `NeuralRadianceField` suffers from\n",
    "    a large memory footprint, which does not let us\n",
    "    render the full image grid in a single forward pass,\n",
    "    we utilize the `NeuralRadianceField.batched_forward`\n",
    "    function in combination with disabling the gradient caching.\n",
    "    This chunks the set of emitted rays to batches and \n",
    "    evaluates the implicit function on one batch at a time\n",
    "    to prevent GPU memory overflow.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        idx = torch.randperm(rays_rgb.shape[0] // (args['image_size']*args['image_size']))[0]\n",
    "        rays_rgb = get_item_from_unshuffled(rays_rgb, idx)\n",
    "        rgb_map, depth_map, target_s = render_full_size_on_cpu(rays_rgb, nerf_fun, coarse_nerf_fun)\n",
    "        \n",
    "        loss = img2mse(rgb_map, target_s)\n",
    "        psnr = mse2psnr(loss)\n",
    "        \n",
    "    if display_figs:\n",
    "        # Generate plots.\n",
    "        rendered_image = rgb_map.reshape((args['image_size'],args['image_size'],3))\n",
    "        target_image = target_s.reshape((args['image_size'],args['image_size'],3))\n",
    "        fig, ax = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        ax = ax.ravel()\n",
    "        clamp_and_detach = lambda x: x.clamp(0.0, 1.0).cpu().detach().numpy()\n",
    "        ax[0].plot(np.arange(len(tcolor)), tcolor, linewidth=1)\n",
    "        ax[1].plot(np.arange(len(vcolor))*val_freq, vcolor, linewidth=1)\n",
    "        ax[2].imshow(clamp_and_detach(rendered_image))\n",
    "        ax[3].plot(np.arange(len(tpsnr)), tpsnr, linewidth=1)\n",
    "        ax[4].plot(np.arange(len(vpsnr))*val_freq, vpsnr, linewidth=1)\n",
    "        ax[5].imshow(clamp_and_detach(target_image))\n",
    "        for ax_, title_ in zip(\n",
    "            ax,\n",
    "            (\n",
    "                \"loss train color\", \"loss val color\", \"rendered image\",\n",
    "                \"loss train psnr\", \"loss val psnr\",\"target val image\",\n",
    "            )\n",
    "        ):\n",
    "            if not title_.startswith('loss'):\n",
    "                ax_.grid(\"off\")\n",
    "                ax_.axis(\"off\")\n",
    "            ax_.set_title(title_)\n",
    "        fig.canvas.draw(); fig.show()\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(fig)\n",
    "    else:\n",
    "        fig = None\n",
    "    return fig, loss, psnr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_save(rays_rgb, files):\n",
    "    rgb_map, depth_map, target_s = render_full_size_on_cpu(rays_rgb, neural_radiance_field, coarse_nerf)\n",
    "    if files[0].split('_')[1] != 'test':\n",
    "        loss = img2mse(rgb_map, target_s)\n",
    "        psnr = mse2psnr(loss)\n",
    "        print(f\"loss: {loss}, psnr: {psnr}\")\n",
    "\n",
    "        with open(os.path.join(args['pred_save_path'], f\"metric.txt\"), 'w') as f:\n",
    "            f.write(f'loss: {loss}, psnr: {psnr}\\n')\n",
    "    else:\n",
    "        loss, psnr = None\n",
    "\n",
    "    rgb_map_resh = rgb_map.reshape((-1, args['image_size'],args['image_size'],3))\n",
    "    depth_map_resh = depth_map.reshape((-1, args['image_size'],args['image_size']))\n",
    "    target_s_resh = target_s.reshape((-1, args['image_size'],args['image_size'],3))\n",
    "\n",
    "    convertnumpy = lambda x: Image.fromarray(np.uint8(x.detach().numpy()*255))\n",
    "    \n",
    "    for i,f in enumerate(files):\n",
    "        basep = os.path.join(args['pred_save_path'], Path(f).stem)\n",
    "        convertnumpy(rgb_map_resh[i]).save(basep + '_rgb.png')\n",
    "        convertnumpy(target_s_resh[i]).save(basep + '_target.png')\n",
    "        convertnumpy(depth_map_resh[i]).save(basep + '_depth.png')\n",
    "        print('saved: ', basep)\n",
    "    return loss, psnr, rgb_map_resh, depth_map_resh, target_s_resh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved:  pred/fine_trained_bottles_200000_800_180_8_2/2_test_0093\n",
      "saved:  pred/fine_trained_bottles_200000_800_180_8_2/2_test_0055\n",
      "saved:  pred/fine_trained_bottles_200000_800_180_8_2/2_test_0160\n",
      "saved:  pred/fine_trained_bottles_200000_800_180_8_2/2_test_0000\n",
      "saved:  pred/fine_trained_bottles_200000_800_180_8_2/2_test_0016\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'loss' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss, psnr, rgb_map_resh, depth_map_resh, target_s_resh \u001b[39m=\u001b[39m gen_save(test_rays_rgb, test_files)\n",
      "Cell \u001b[0;32mIn [11], line 23\u001b[0m, in \u001b[0;36mgen_save\u001b[0;34m(rays_rgb, files)\u001b[0m\n\u001b[1;32m     21\u001b[0m     convertnumpy(depth_map_resh[i])\u001b[39m.\u001b[39msave(basep \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_depth.png\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39msaved: \u001b[39m\u001b[39m'\u001b[39m, basep)\n\u001b[0;32m---> 23\u001b[0m \u001b[39mreturn\u001b[39;00m loss, psnr, rgb_map_resh, depth_map_resh, target_s_resh\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'loss' referenced before assignment"
     ]
    }
   ],
   "source": [
    "loss, psnr, rgb_map_resh, depth_map_resh, target_s_resh = gen_save(test_rays_rgb, test_files)\n",
    "# loss, psnr, rgb_map_resh, depth_map_resh, target_s_resh = gen_save(val_rays_rgb, val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "3bfcdb114524e2ba8fe0194fc78ceb166e5028eb0d6d0612135b4c451466bd71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
